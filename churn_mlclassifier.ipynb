{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912531b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "x_train shape: (284152, 32)\n",
      "x_test shape: (71038, 32)\n",
      "y_train shape: (284152,)\n",
      "y_test shape: (71038,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CR_PROD_CNT_IL</th>\n",
       "      <th>TURNOVER_DYNAMIC_IL_1M</th>\n",
       "      <th>REST_DYNAMIC_FDEP_1M</th>\n",
       "      <th>REST_DYNAMIC_SAVE_3M</th>\n",
       "      <th>CR_PROD_CNT_VCU</th>\n",
       "      <th>REST_AVG_CUR</th>\n",
       "      <th>CR_PROD_CNT_TOVR</th>\n",
       "      <th>CR_PROD_CNT_PIL</th>\n",
       "      <th>TURNOVER_CC</th>\n",
       "      <th>TURNOVER_PAYM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>CR_PROD_CNT_CC</th>\n",
       "      <th>REST_DYNAMIC_FDEP_3M</th>\n",
       "      <th>REST_DYNAMIC_IL_1M</th>\n",
       "      <th>CR_PROD_CNT_CCFP</th>\n",
       "      <th>REST_DYNAMIC_CUR_1M</th>\n",
       "      <th>REST_AVG_PAYM</th>\n",
       "      <th>LDEAL_GRACE_DAYS_PCT_MED</th>\n",
       "      <th>REST_DYNAMIC_CUR_3M</th>\n",
       "      <th>TURNOVER_DYNAMIC_CUR_1M</th>\n",
       "      <th>REST_DYNAMIC_PAYM_3M</th>\n",
       "      <th>REST_DYNAMIC_IL_3M</th>\n",
       "      <th>TURNOVER_DYNAMIC_IL_3M</th>\n",
       "      <th>REST_DYNAMIC_PAYM_1M</th>\n",
       "      <th>TURNOVER_DYNAMIC_CUR_3M</th>\n",
       "      <th>CLNT_SETUP_TENOR</th>\n",
       "      <th>TURNOVER_DYNAMIC_PAYM_3M</th>\n",
       "      <th>TURNOVER_DYNAMIC_PAYM_1M</th>\n",
       "      <th>REST_DYNAMIC_CC_1M</th>\n",
       "      <th>TURNOVER_DYNAMIC_CC_1M</th>\n",
       "      <th>REST_DYNAMIC_CC_3M</th>\n",
       "      <th>TURNOVER_DYNAMIC_CC_3M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.061893</td>\n",
       "      <td>-0.044935</td>\n",
       "      <td>-0.052273</td>\n",
       "      <td>-0.312231</td>\n",
       "      <td>5.244695</td>\n",
       "      <td>-0.110851</td>\n",
       "      <td>1.176112</td>\n",
       "      <td>-0.192559</td>\n",
       "      <td>-0.038441</td>\n",
       "      <td>-0.093385</td>\n",
       "      <td>-0.976263</td>\n",
       "      <td>-0.242002</td>\n",
       "      <td>-0.086736</td>\n",
       "      <td>-0.068473</td>\n",
       "      <td>-0.064618</td>\n",
       "      <td>0.258930</td>\n",
       "      <td>-0.151018</td>\n",
       "      <td>-0.045033</td>\n",
       "      <td>0.283547</td>\n",
       "      <td>0.190178</td>\n",
       "      <td>-0.375206</td>\n",
       "      <td>-0.099585</td>\n",
       "      <td>-0.075343</td>\n",
       "      <td>-0.284607</td>\n",
       "      <td>0.326273</td>\n",
       "      <td>-0.610612</td>\n",
       "      <td>-0.347538</td>\n",
       "      <td>-0.24017</td>\n",
       "      <td>-0.083058</td>\n",
       "      <td>-0.031616</td>\n",
       "      <td>-0.108653</td>\n",
       "      <td>-0.07104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.244365</td>\n",
       "      <td>-0.044935</td>\n",
       "      <td>-0.052273</td>\n",
       "      <td>2.151389</td>\n",
       "      <td>-0.169621</td>\n",
       "      <td>0.192015</td>\n",
       "      <td>-0.526426</td>\n",
       "      <td>-0.192559</td>\n",
       "      <td>-0.038441</td>\n",
       "      <td>-0.093385</td>\n",
       "      <td>-1.064184</td>\n",
       "      <td>-0.242002</td>\n",
       "      <td>-0.086736</td>\n",
       "      <td>-0.068473</td>\n",
       "      <td>-0.064618</td>\n",
       "      <td>-0.286218</td>\n",
       "      <td>-0.151018</td>\n",
       "      <td>-0.045033</td>\n",
       "      <td>-0.227630</td>\n",
       "      <td>0.140643</td>\n",
       "      <td>-0.375206</td>\n",
       "      <td>-0.099585</td>\n",
       "      <td>-0.075343</td>\n",
       "      <td>-0.284607</td>\n",
       "      <td>-0.316017</td>\n",
       "      <td>1.144931</td>\n",
       "      <td>-0.347538</td>\n",
       "      <td>-0.24017</td>\n",
       "      <td>-0.083058</td>\n",
       "      <td>-0.031616</td>\n",
       "      <td>-0.108653</td>\n",
       "      <td>-0.07104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.244365</td>\n",
       "      <td>-0.044935</td>\n",
       "      <td>-0.052273</td>\n",
       "      <td>-0.312231</td>\n",
       "      <td>-0.169621</td>\n",
       "      <td>-0.260938</td>\n",
       "      <td>-0.526426</td>\n",
       "      <td>-0.192559</td>\n",
       "      <td>-0.038441</td>\n",
       "      <td>-0.093385</td>\n",
       "      <td>1.837201</td>\n",
       "      <td>-0.242002</td>\n",
       "      <td>-0.086736</td>\n",
       "      <td>-0.068473</td>\n",
       "      <td>-0.064618</td>\n",
       "      <td>-0.433742</td>\n",
       "      <td>-0.151018</td>\n",
       "      <td>-0.045033</td>\n",
       "      <td>-0.448334</td>\n",
       "      <td>-0.392441</td>\n",
       "      <td>-0.375206</td>\n",
       "      <td>-0.099585</td>\n",
       "      <td>-0.075343</td>\n",
       "      <td>-0.284607</td>\n",
       "      <td>-0.661855</td>\n",
       "      <td>-1.081618</td>\n",
       "      <td>-0.347538</td>\n",
       "      <td>-0.24017</td>\n",
       "      <td>-0.083058</td>\n",
       "      <td>-0.031616</td>\n",
       "      <td>-0.108653</td>\n",
       "      <td>-0.07104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.061893</td>\n",
       "      <td>-0.044935</td>\n",
       "      <td>-0.052273</td>\n",
       "      <td>-0.312231</td>\n",
       "      <td>-0.169621</td>\n",
       "      <td>-0.332548</td>\n",
       "      <td>1.176112</td>\n",
       "      <td>-0.192559</td>\n",
       "      <td>-0.038441</td>\n",
       "      <td>-0.093385</td>\n",
       "      <td>-0.184976</td>\n",
       "      <td>-0.242002</td>\n",
       "      <td>-0.086736</td>\n",
       "      <td>-0.068473</td>\n",
       "      <td>-0.064618</td>\n",
       "      <td>0.039323</td>\n",
       "      <td>-0.151018</td>\n",
       "      <td>-0.045033</td>\n",
       "      <td>0.836577</td>\n",
       "      <td>0.003751</td>\n",
       "      <td>-0.375206</td>\n",
       "      <td>-0.099585</td>\n",
       "      <td>-0.075343</td>\n",
       "      <td>-0.284607</td>\n",
       "      <td>0.899380</td>\n",
       "      <td>-0.425565</td>\n",
       "      <td>-0.347538</td>\n",
       "      <td>-0.24017</td>\n",
       "      <td>-0.083058</td>\n",
       "      <td>-0.031616</td>\n",
       "      <td>-0.108653</td>\n",
       "      <td>-0.07104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.244365</td>\n",
       "      <td>-0.044935</td>\n",
       "      <td>-0.052273</td>\n",
       "      <td>-0.312231</td>\n",
       "      <td>-0.169621</td>\n",
       "      <td>-0.291020</td>\n",
       "      <td>1.176112</td>\n",
       "      <td>-0.192559</td>\n",
       "      <td>-0.038441</td>\n",
       "      <td>-0.093385</td>\n",
       "      <td>-1.327946</td>\n",
       "      <td>-0.242002</td>\n",
       "      <td>-0.086736</td>\n",
       "      <td>-0.068473</td>\n",
       "      <td>-0.064618</td>\n",
       "      <td>0.799208</td>\n",
       "      <td>-0.151018</td>\n",
       "      <td>-0.045033</td>\n",
       "      <td>1.675035</td>\n",
       "      <td>1.528313</td>\n",
       "      <td>-0.375206</td>\n",
       "      <td>-0.099585</td>\n",
       "      <td>-0.075343</td>\n",
       "      <td>-0.284607</td>\n",
       "      <td>1.554690</td>\n",
       "      <td>-0.719649</td>\n",
       "      <td>-0.347538</td>\n",
       "      <td>-0.24017</td>\n",
       "      <td>-0.083058</td>\n",
       "      <td>-0.031616</td>\n",
       "      <td>-0.108653</td>\n",
       "      <td>-0.07104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CR_PROD_CNT_IL  TURNOVER_DYNAMIC_IL_1M  REST_DYNAMIC_FDEP_1M  \\\n",
       "0        2.061893               -0.044935             -0.052273   \n",
       "1       -0.244365               -0.044935             -0.052273   \n",
       "2       -0.244365               -0.044935             -0.052273   \n",
       "3        2.061893               -0.044935             -0.052273   \n",
       "4       -0.244365               -0.044935             -0.052273   \n",
       "\n",
       "   REST_DYNAMIC_SAVE_3M  CR_PROD_CNT_VCU  REST_AVG_CUR  CR_PROD_CNT_TOVR  \\\n",
       "0             -0.312231         5.244695     -0.110851          1.176112   \n",
       "1              2.151389        -0.169621      0.192015         -0.526426   \n",
       "2             -0.312231        -0.169621     -0.260938         -0.526426   \n",
       "3             -0.312231        -0.169621     -0.332548          1.176112   \n",
       "4             -0.312231        -0.169621     -0.291020          1.176112   \n",
       "\n",
       "   CR_PROD_CNT_PIL  TURNOVER_CC  TURNOVER_PAYM       AGE  CR_PROD_CNT_CC  \\\n",
       "0        -0.192559    -0.038441      -0.093385 -0.976263       -0.242002   \n",
       "1        -0.192559    -0.038441      -0.093385 -1.064184       -0.242002   \n",
       "2        -0.192559    -0.038441      -0.093385  1.837201       -0.242002   \n",
       "3        -0.192559    -0.038441      -0.093385 -0.184976       -0.242002   \n",
       "4        -0.192559    -0.038441      -0.093385 -1.327946       -0.242002   \n",
       "\n",
       "   REST_DYNAMIC_FDEP_3M  REST_DYNAMIC_IL_1M  CR_PROD_CNT_CCFP  \\\n",
       "0             -0.086736           -0.068473         -0.064618   \n",
       "1             -0.086736           -0.068473         -0.064618   \n",
       "2             -0.086736           -0.068473         -0.064618   \n",
       "3             -0.086736           -0.068473         -0.064618   \n",
       "4             -0.086736           -0.068473         -0.064618   \n",
       "\n",
       "   REST_DYNAMIC_CUR_1M  REST_AVG_PAYM  LDEAL_GRACE_DAYS_PCT_MED  \\\n",
       "0             0.258930      -0.151018                 -0.045033   \n",
       "1            -0.286218      -0.151018                 -0.045033   \n",
       "2            -0.433742      -0.151018                 -0.045033   \n",
       "3             0.039323      -0.151018                 -0.045033   \n",
       "4             0.799208      -0.151018                 -0.045033   \n",
       "\n",
       "   REST_DYNAMIC_CUR_3M  TURNOVER_DYNAMIC_CUR_1M  REST_DYNAMIC_PAYM_3M  \\\n",
       "0             0.283547                 0.190178             -0.375206   \n",
       "1            -0.227630                 0.140643             -0.375206   \n",
       "2            -0.448334                -0.392441             -0.375206   \n",
       "3             0.836577                 0.003751             -0.375206   \n",
       "4             1.675035                 1.528313             -0.375206   \n",
       "\n",
       "   REST_DYNAMIC_IL_3M  TURNOVER_DYNAMIC_IL_3M  REST_DYNAMIC_PAYM_1M  \\\n",
       "0           -0.099585               -0.075343             -0.284607   \n",
       "1           -0.099585               -0.075343             -0.284607   \n",
       "2           -0.099585               -0.075343             -0.284607   \n",
       "3           -0.099585               -0.075343             -0.284607   \n",
       "4           -0.099585               -0.075343             -0.284607   \n",
       "\n",
       "   TURNOVER_DYNAMIC_CUR_3M  CLNT_SETUP_TENOR  TURNOVER_DYNAMIC_PAYM_3M  \\\n",
       "0                 0.326273         -0.610612                 -0.347538   \n",
       "1                -0.316017          1.144931                 -0.347538   \n",
       "2                -0.661855         -1.081618                 -0.347538   \n",
       "3                 0.899380         -0.425565                 -0.347538   \n",
       "4                 1.554690         -0.719649                 -0.347538   \n",
       "\n",
       "   TURNOVER_DYNAMIC_PAYM_1M  REST_DYNAMIC_CC_1M  TURNOVER_DYNAMIC_CC_1M  \\\n",
       "0                  -0.24017           -0.083058               -0.031616   \n",
       "1                  -0.24017           -0.083058               -0.031616   \n",
       "2                  -0.24017           -0.083058               -0.031616   \n",
       "3                  -0.24017           -0.083058               -0.031616   \n",
       "4                  -0.24017           -0.083058               -0.031616   \n",
       "\n",
       "   REST_DYNAMIC_CC_3M  TURNOVER_DYNAMIC_CC_3M  \n",
       "0           -0.108653                -0.07104  \n",
       "1           -0.108653                -0.07104  \n",
       "2           -0.108653                -0.07104  \n",
       "3           -0.108653                -0.07104  \n",
       "4           -0.108653                -0.07104  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install dependencies (add imbalanced-learn)\n",
    "%pip install pandas matplotlib scikit-learn imbalanced-learn --quiet\n",
    "\n",
    "from features import get_train_test_data\n",
    "\n",
    "x_train, x_test, y_train, y_test = get_train_test_data(\"data/bank_data_train.csv\")\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Display first 5 rows of x_train\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4e539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used for training: ['CR_PROD_CNT_IL', 'TURNOVER_DYNAMIC_IL_1M', 'REST_DYNAMIC_FDEP_1M', 'REST_DYNAMIC_SAVE_3M', 'CR_PROD_CNT_VCU', 'REST_AVG_CUR', 'CR_PROD_CNT_TOVR', 'CR_PROD_CNT_PIL', 'TURNOVER_CC', 'TURNOVER_PAYM', 'AGE', 'CR_PROD_CNT_CC', 'REST_DYNAMIC_FDEP_3M', 'REST_DYNAMIC_IL_1M', 'CR_PROD_CNT_CCFP', 'REST_DYNAMIC_CUR_1M', 'REST_AVG_PAYM', 'LDEAL_GRACE_DAYS_PCT_MED', 'REST_DYNAMIC_CUR_3M', 'TURNOVER_DYNAMIC_CUR_1M', 'REST_DYNAMIC_PAYM_3M', 'REST_DYNAMIC_IL_3M', 'TURNOVER_DYNAMIC_IL_3M', 'REST_DYNAMIC_PAYM_1M', 'TURNOVER_DYNAMIC_CUR_3M', 'CLNT_SETUP_TENOR', 'TURNOVER_DYNAMIC_PAYM_3M', 'TURNOVER_DYNAMIC_PAYM_1M', 'REST_DYNAMIC_CC_1M', 'TURNOVER_DYNAMIC_CC_1M', 'REST_DYNAMIC_CC_3M', 'TURNOVER_DYNAMIC_CC_3M']\n"
     ]
    }
   ],
   "source": [
    "# print name of features used for training\n",
    "print(f\"Features used for training: {x_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb1d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.26313324\n",
      "Iteration 2, loss = 0.24592634\n",
      "Iteration 3, loss = 0.24150953\n",
      "Iteration 4, loss = 0.23893133\n",
      "Iteration 5, loss = 0.23740801\n",
      "Iteration 6, loss = 0.23570185\n",
      "Iteration 7, loss = 0.23436990\n",
      "Iteration 8, loss = 0.23338981\n",
      "Iteration 9, loss = 0.23247321\n",
      "Iteration 10, loss = 0.23169057\n",
      "Iteration 11, loss = 0.23086432\n",
      "Iteration 12, loss = 0.23029109\n",
      "Iteration 13, loss = 0.22966043\n",
      "Iteration 14, loss = 0.22926212\n",
      "Iteration 15, loss = 0.22907618\n",
      "Iteration 16, loss = 0.22842395\n",
      "Iteration 17, loss = 0.22815834\n",
      "Iteration 18, loss = 0.22812102\n",
      "Iteration 19, loss = 0.22759946\n",
      "Iteration 20, loss = 0.22728971\n",
      "Iteration 21, loss = 0.22716113\n",
      "Iteration 22, loss = 0.22688744\n",
      "Iteration 23, loss = 0.22674421\n",
      "Iteration 24, loss = 0.22637262\n",
      "Iteration 25, loss = 0.22625498\n",
      "Iteration 26, loss = 0.22579211\n",
      "Iteration 27, loss = 0.22576219\n",
      "Iteration 28, loss = 0.22551214\n",
      "Iteration 29, loss = 0.22532228\n",
      "Iteration 30, loss = 0.22518901\n",
      "Iteration 31, loss = 0.22484191\n",
      "Iteration 32, loss = 0.22475392\n",
      "Iteration 33, loss = 0.22461887\n",
      "Iteration 34, loss = 0.22424544\n",
      "Iteration 35, loss = 0.22399765\n",
      "Iteration 36, loss = 0.22446159\n",
      "Iteration 37, loss = 0.22382224\n",
      "Iteration 38, loss = 0.22367831\n",
      "Iteration 39, loss = 0.22368074\n",
      "Iteration 40, loss = 0.22342770\n",
      "Iteration 41, loss = 0.22337040\n",
      "Iteration 42, loss = 0.22298048\n",
      "Iteration 43, loss = 0.22280855\n",
      "Iteration 44, loss = 0.22304741\n",
      "Iteration 45, loss = 0.22271812\n",
      "Iteration 46, loss = 0.22245073\n",
      "Iteration 47, loss = 0.22249303\n",
      "Iteration 48, loss = 0.22224473\n",
      "Iteration 49, loss = 0.22235065\n",
      "Iteration 50, loss = 0.22210943\n",
      "Iteration 51, loss = 0.22187605\n",
      "Iteration 52, loss = 0.22177399\n",
      "Iteration 53, loss = 0.22167202\n",
      "Iteration 54, loss = 0.22143401\n",
      "Iteration 55, loss = 0.22163459\n",
      "Iteration 56, loss = 0.22167478\n",
      "Iteration 57, loss = 0.22112695\n",
      "Iteration 58, loss = 0.22124651\n",
      "Iteration 59, loss = 0.22106624\n",
      "Iteration 60, loss = 0.22107984\n",
      "Iteration 61, loss = 0.22090795\n",
      "Iteration 62, loss = 0.22079150\n",
      "Iteration 63, loss = 0.22071737\n",
      "Iteration 64, loss = 0.22063391\n",
      "Iteration 65, loss = 0.22055235\n",
      "Iteration 66, loss = 0.22053896\n",
      "Iteration 67, loss = 0.22025425\n",
      "Iteration 68, loss = 0.22028396\n",
      "Iteration 69, loss = 0.22015553\n",
      "Iteration 70, loss = 0.21988677\n",
      "Iteration 71, loss = 0.21984792\n",
      "Iteration 72, loss = 0.21975635\n",
      "Iteration 73, loss = 0.21978178\n",
      "Iteration 74, loss = 0.21974342\n",
      "Iteration 75, loss = 0.21964179\n",
      "Iteration 76, loss = 0.21947241\n",
      "Iteration 77, loss = 0.21940986\n",
      "Iteration 78, loss = 0.21925404\n",
      "Iteration 79, loss = 0.21917955\n",
      "Iteration 80, loss = 0.21907136\n",
      "Iteration 81, loss = 0.21898641\n",
      "Iteration 82, loss = 0.21884477\n",
      "Iteration 83, loss = 0.21897638\n",
      "Iteration 84, loss = 0.21873614\n",
      "Iteration 85, loss = 0.21870347\n",
      "Iteration 86, loss = 0.21881073\n",
      "Iteration 87, loss = 0.21863704\n",
      "Iteration 88, loss = 0.21862015\n",
      "Iteration 89, loss = 0.21861449\n",
      "Iteration 90, loss = 0.21836129\n",
      "Iteration 91, loss = 0.21819342\n",
      "Iteration 92, loss = 0.21809834\n",
      "Iteration 93, loss = 0.21834035\n",
      "Iteration 94, loss = 0.21798533\n",
      "Iteration 95, loss = 0.21777574\n",
      "Iteration 96, loss = 0.21800460\n",
      "Iteration 97, loss = 0.21786674\n",
      "Iteration 98, loss = 0.21768988\n",
      "Iteration 99, loss = 0.21779456\n",
      "Iteration 100, loss = 0.21762529\n",
      "Iteration 101, loss = 0.21744217\n",
      "Iteration 102, loss = 0.21741523\n",
      "Iteration 103, loss = 0.21742421\n",
      "Iteration 104, loss = 0.21745607\n",
      "Iteration 105, loss = 0.21720878\n",
      "Iteration 106, loss = 0.21726685\n",
      "Iteration 107, loss = 0.21742945\n",
      "Iteration 108, loss = 0.21711348\n",
      "Iteration 109, loss = 0.21674009\n",
      "Iteration 110, loss = 0.21710695\n",
      "Iteration 111, loss = 0.21692107\n",
      "Iteration 112, loss = 0.21683697\n",
      "Iteration 113, loss = 0.21686148\n",
      "Iteration 114, loss = 0.21654695\n",
      "Iteration 115, loss = 0.21659789\n",
      "Iteration 116, loss = 0.21673658\n",
      "Iteration 117, loss = 0.21644495\n",
      "Iteration 118, loss = 0.21639454\n",
      "Iteration 119, loss = 0.21658411\n",
      "Iteration 120, loss = 0.21651457\n",
      "Iteration 121, loss = 0.21625239\n",
      "Iteration 122, loss = 0.21646267\n",
      "Iteration 123, loss = 0.21657505\n",
      "Iteration 124, loss = 0.21637265\n",
      "Iteration 125, loss = 0.21600311\n",
      "Iteration 126, loss = 0.21610490\n",
      "Iteration 127, loss = 0.21625441\n",
      "Iteration 128, loss = 0.21589491\n",
      "Iteration 129, loss = 0.21619076\n",
      "Iteration 130, loss = 0.21597373\n",
      "Iteration 131, loss = 0.21586113\n",
      "Iteration 132, loss = 0.21609930\n",
      "Iteration 133, loss = 0.21596277\n",
      "Iteration 134, loss = 0.21579924\n",
      "Iteration 135, loss = 0.21576491\n",
      "Iteration 136, loss = 0.21564380\n",
      "Iteration 137, loss = 0.21551309\n",
      "Iteration 138, loss = 0.21555584\n",
      "Iteration 139, loss = 0.21562186\n",
      "Iteration 140, loss = 0.21545712\n",
      "Iteration 141, loss = 0.21544983\n",
      "Iteration 142, loss = 0.21526418\n",
      "Iteration 143, loss = 0.21553305\n",
      "Iteration 144, loss = 0.21535207\n",
      "Iteration 145, loss = 0.21551123\n",
      "Iteration 146, loss = 0.21532451\n",
      "Iteration 147, loss = 0.21551055\n",
      "Iteration 148, loss = 0.21523274\n",
      "Iteration 149, loss = 0.21498976\n",
      "Iteration 150, loss = 0.21529454\n",
      "Iteration 151, loss = 0.21519654\n",
      "Iteration 152, loss = 0.21516448\n",
      "Iteration 153, loss = 0.21514416\n",
      "Iteration 154, loss = 0.21489694\n",
      "Iteration 155, loss = 0.21488053\n",
      "Iteration 156, loss = 0.21483855\n",
      "Iteration 157, loss = 0.21493110\n",
      "Iteration 158, loss = 0.21481864\n",
      "Iteration 159, loss = 0.21487366\n",
      "Iteration 160, loss = 0.21471611\n",
      "Iteration 161, loss = 0.21467145\n",
      "Iteration 162, loss = 0.21468170\n",
      "Iteration 163, loss = 0.21462124\n",
      "Iteration 164, loss = 0.21470213\n",
      "Iteration 165, loss = 0.21452519\n",
      "Iteration 166, loss = 0.21489360\n",
      "Iteration 167, loss = 0.21464483\n",
      "Iteration 168, loss = 0.21458991\n",
      "Iteration 169, loss = 0.21446947\n",
      "Iteration 170, loss = 0.21435543\n",
      "Iteration 171, loss = 0.21442001\n",
      "Iteration 172, loss = 0.21457249\n",
      "Iteration 173, loss = 0.21444728\n",
      "Iteration 174, loss = 0.21431469\n",
      "Iteration 175, loss = 0.21441637\n",
      "Iteration 176, loss = 0.21445655\n",
      "Iteration 177, loss = 0.21443323\n",
      "Iteration 178, loss = 0.21415537\n",
      "Iteration 179, loss = 0.21433815\n",
      "Iteration 180, loss = 0.21398771\n",
      "Iteration 181, loss = 0.21407043\n",
      "Iteration 182, loss = 0.21387964\n",
      "Iteration 183, loss = 0.21401452\n",
      "Iteration 184, loss = 0.21411228\n",
      "Iteration 185, loss = 0.21394827\n",
      "Iteration 186, loss = 0.21393989\n",
      "Iteration 187, loss = 0.21418012\n",
      "Iteration 188, loss = 0.21412492\n",
      "Iteration 189, loss = 0.21387803\n",
      "Iteration 190, loss = 0.21397255\n",
      "Iteration 191, loss = 0.21402594\n",
      "Iteration 192, loss = 0.21390363\n",
      "Iteration 193, loss = 0.21413384\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     65253\n",
      "           1       0.42      0.06      0.11      5785\n",
      "\n",
      "    accuracy                           0.92     71038\n",
      "   macro avg       0.67      0.53      0.53     71038\n",
      "weighted avg       0.88      0.92      0.89     71038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    max_iter=300,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed79171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test AUC: 0.8071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get predictions\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_proba = model.predict_proba(x_test)[:, 1]  # Probabilities for AUC\n",
    "\n",
    "# Print AUC\n",
    "test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"Test AUC: {test_auc:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
